{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch.utils.data\n",
    "from scipy import misc\n",
    "from torch import optim\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm, trange\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "from transformers import AutoTokenizer, BertTokenizer, BertModel, BertForSequenceClassification\n",
    "from collections import namedtuple\n",
    "import torchvision.models as models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from laserembeddings import Laser\n",
    "\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable gpu device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 8899\n",
    "# SEED = 8888\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = os.path.join('../../..', 'MVAE', 'mediaeval2016', 'images_train')\n",
    "test_img_dir = os.path.join('../../..', 'MVAE', 'mediaeval2016', 'images_test')\n",
    "\n",
    "# load training label\n",
    "train_df = pd.read_csv('~/adversarial_learning/MVAE/mediaeval2016/train_posts.txt', sep='\\t')\n",
    "# load test label\n",
    "test_df = pd.read_csv('~/adversarial_learning/MVAE/mediaeval2016/test_posts.txt', sep='\\t')\n",
    "# test_df = pd.read_csv('~/adversarial_learning/MVAE/mediaeval2016/test_posts_attacks/test_posts_notext.txt', sep='\\t')\n",
    "# test_df = pd.read_csv('~/adversarial_learning/MVAE/mediaeval2016/test_posts_attacks/test_posts_all_fake.txt', sep='\\t')\n",
    "# test_df = pd.read_csv('~/adversarial_learning/MVAE/mediaeval2016/test_posts_charswap_rm_error_line.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.562900e+04</td>\n",
       "      <td>1.562900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.516204e+17</td>\n",
       "      <td>4.610838e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.299838e+17</td>\n",
       "      <td>6.592920e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.615730e+17</td>\n",
       "      <td>1.117000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.631248e+17</td>\n",
       "      <td>6.819622e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.641468e+17</td>\n",
       "      <td>2.442158e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.100905e+17</td>\n",
       "      <td>4.852363e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.956985e+17</td>\n",
       "      <td>3.229452e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            post_id       user_id\n",
       "count  1.562900e+04  1.562900e+04\n",
       "mean   3.516204e+17  4.610838e+08\n",
       "std    1.299838e+17  6.592920e+08\n",
       "min    2.615730e+17  1.117000e+03\n",
       "25%    2.631248e+17  6.819622e+07\n",
       "50%    2.641468e+17  2.442158e+08\n",
       "75%    5.100905e+17  4.852363e+08\n",
       "max    5.956985e+17  3.229452e+09"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>image_id(s)</th>\n",
       "      <th>username</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>324597532548276224</td>\n",
       "      <td>Don't need feds to solve the #bostonbombing wh...</td>\n",
       "      <td>886672620</td>\n",
       "      <td>boston_fake_03,boston_fake_35</td>\n",
       "      <td>SantaCruzShred</td>\n",
       "      <td>Wed Apr 17 18:57:37 +0000 2013</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325145334739267584</td>\n",
       "      <td>PIC: Comparison of #Boston suspect Sunil Tripa...</td>\n",
       "      <td>21992286</td>\n",
       "      <td>boston_fake_23</td>\n",
       "      <td>Oscar_Wang</td>\n",
       "      <td>Fri Apr 19 07:14:23 +0000 2013</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>325152091423248385</td>\n",
       "      <td>I'm not completely convinced that it's this Su...</td>\n",
       "      <td>16428755</td>\n",
       "      <td>boston_fake_34</td>\n",
       "      <td>jamwil</td>\n",
       "      <td>Fri Apr 19 07:41:14 +0000 2013</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324554646976868352</td>\n",
       "      <td>Brutal lo que se puede conseguir en colaboraci...</td>\n",
       "      <td>303138574</td>\n",
       "      <td>boston_fake_03,boston_fake_35</td>\n",
       "      <td>rubenson80</td>\n",
       "      <td>Wed Apr 17 16:07:12 +0000 2013</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>324315545572896768</td>\n",
       "      <td>4chan and the bombing. just throwing it out th...</td>\n",
       "      <td>180460772</td>\n",
       "      <td>boston_fake_15</td>\n",
       "      <td>Slimlenny</td>\n",
       "      <td>Wed Apr 17 00:17:06 +0000 2013</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              post_id                                          post_text  \\\n",
       "0  324597532548276224  Don't need feds to solve the #bostonbombing wh...   \n",
       "1  325145334739267584  PIC: Comparison of #Boston suspect Sunil Tripa...   \n",
       "2  325152091423248385  I'm not completely convinced that it's this Su...   \n",
       "3  324554646976868352  Brutal lo que se puede conseguir en colaboraci...   \n",
       "4  324315545572896768  4chan and the bombing. just throwing it out th...   \n",
       "\n",
       "     user_id                    image_id(s)        username  \\\n",
       "0  886672620  boston_fake_03,boston_fake_35  SantaCruzShred   \n",
       "1   21992286                 boston_fake_23      Oscar_Wang   \n",
       "2   16428755                 boston_fake_34          jamwil   \n",
       "3  303138574  boston_fake_03,boston_fake_35      rubenson80   \n",
       "4  180460772                 boston_fake_15       Slimlenny   \n",
       "\n",
       "                        timestamp label  \n",
       "0  Wed Apr 17 18:57:37 +0000 2013  fake  \n",
       "1  Fri Apr 19 07:14:23 +0000 2013  fake  \n",
       "2  Fri Apr 19 07:41:14 +0000 2013  fake  \n",
       "3  Wed Apr 17 16:07:12 +0000 2013  fake  \n",
       "4  Wed Apr 17 00:17:06 +0000 2013  fake  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>image_id(s)</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>651118294447951872</td>\n",
       "      <td>blank</td>\n",
       "      <td>3.834097e+08</td>\n",
       "      <td>AlexArtAndros</td>\n",
       "      <td>airstrikes_1</td>\n",
       "      <td>Mon Oct 05 19:34:33 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>651115824065830912</td>\n",
       "      <td>blank</td>\n",
       "      <td>3.834097e+08</td>\n",
       "      <td>AlexArtAndros</td>\n",
       "      <td>airstrikes_1</td>\n",
       "      <td>Mon Oct 05 19:24:44 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>651095856662360065</td>\n",
       "      <td>blank</td>\n",
       "      <td>2.712310e+09</td>\n",
       "      <td>NataYaraya</td>\n",
       "      <td>airstrikes_1</td>\n",
       "      <td>Mon Oct 05 18:05:23 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>651086828234104832</td>\n",
       "      <td>blank</td>\n",
       "      <td>3.690572e+07</td>\n",
       "      <td>Alltecz</td>\n",
       "      <td>airstrikes_1</td>\n",
       "      <td>Mon Oct 05 17:29:31 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>651034616007106560</td>\n",
       "      <td>blank</td>\n",
       "      <td>1.070959e+09</td>\n",
       "      <td>msojormsojor</td>\n",
       "      <td>airstrikes_1</td>\n",
       "      <td>Mon Oct 05 14:02:02 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              post_id post_text       user_id       username   image_id(s)  \\\n",
       "0  651118294447951872     blank  3.834097e+08  AlexArtAndros  airstrikes_1   \n",
       "1  651115824065830912     blank  3.834097e+08  AlexArtAndros  airstrikes_1   \n",
       "2  651095856662360065     blank  2.712310e+09     NataYaraya  airstrikes_1   \n",
       "3  651086828234104832     blank  3.690572e+07        Alltecz  airstrikes_1   \n",
       "4  651034616007106560     blank  1.070959e+09   msojormsojor  airstrikes_1   \n",
       "\n",
       "                        timestamp label  \n",
       "0  Mon Oct 05 19:34:33 +0000 2015  fake  \n",
       "1  Mon Oct 05 19:24:44 +0000 2015  fake  \n",
       "2  Mon Oct 05 18:05:23 +0000 2015  fake  \n",
       "3  Mon Oct 05 17:29:31 +0000 2015  fake  \n",
       "4  Mon Oct 05 14:02:02 +0000 2015  fake  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_first_image(row):\n",
    "    return row['image_id(s)'].split(',')[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22651d3b9655448782236886604de399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15629 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['first_image_id'] = train_df.progress_apply (lambda row: return_first_image(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boston_fake_35',\n",
       " 'eclipse_video_01',\n",
       " 'sandy_real_09',\n",
       " 'sandy_real_10',\n",
       " 'sandy_real_4',\n",
       " 'sandy_real_6',\n",
       " 'sandy_real_90',\n",
       " 'syrianboy_1',\n",
       " 'varoufakis_1'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train_dataset = [i for i in train_df['first_image_id'].tolist()]\n",
    "images_train_folder = [i.split('.')[0].strip() for i in os.listdir(train_img_dir)]\n",
    "images_train_not_available = set(images_train_dataset)-set(images_train_folder)\n",
    "images_train_not_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airstrikes_1',\n",
       " 'american_soldier_quran_1',\n",
       " 'ankara_explosions_1',\n",
       " 'ankara_explosions_2',\n",
       " 'ankara_explosions_3',\n",
       " 'attacks_paris_16',\n",
       " 'attacks_paris_24',\n",
       " 'attacks_paris_7',\n",
       " 'boko_haram_1',\n",
       " 'brussels_car_metro_1',\n",
       " 'brussels_car_metro_2',\n",
       " 'brussels_car_metro_3',\n",
       " 'brussels_explosions_1',\n",
       " 'brussels_explosions_2',\n",
       " 'brussels_explosions_3',\n",
       " 'convoy_explosion_turkey_1',\n",
       " 'convoy_explosion_turkey_2',\n",
       " 'convoy_explosion_turkey_3',\n",
       " 'donald_trump_attacker_1',\n",
       " 'eagle_kid_1',\n",
       " 'immigrants_1',\n",
       " 'immigrants_2',\n",
       " 'immigrants_3',\n",
       " 'immigrants_4',\n",
       " 'immigrants_5',\n",
       " 'immigrants_6',\n",
       " 'immigrants_7',\n",
       " 'immigrants_8',\n",
       " 'isis_children_1',\n",
       " 'isis_children_2',\n",
       " 'nazi_submarine_2',\n",
       " 'pope_francis_1',\n",
       " 'snowboard_girl_1',\n",
       " 'snowboard_girl_2',\n",
       " 'syrian_children_2'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_test_dataset = [i.split(',')[0].strip() for i in test_df['image_id(s)'].tolist()]\n",
    "images_test_folder = [i.split('.')[0].strip() for i in listdir(test_img_dir)]\n",
    "images_test_not_available = set(images_test_dataset)-set(images_test_folder)\n",
    "images_test_not_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train_not_available.add('boston_fake_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[~train_df['first_image_id'].isin(images_train_not_available)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[~test_df['image_id(s)'].isin(images_test_not_available)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13407, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eclipse': 0,\n",
       " 'columbianChemicals': 1,\n",
       " 'passport': 2,\n",
       " 'underwater': 3,\n",
       " 'nepal': 4,\n",
       " 'sandy': 5,\n",
       " 'boston': 6,\n",
       " 'garissa': 7,\n",
       " 'samurai': 8,\n",
       " 'livr': 9,\n",
       " 'elephant': 10,\n",
       " 'malaysia': 11,\n",
       " 'bringback': 12,\n",
       " 'pigFish': 13,\n",
       " 'sochi': 14}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# already exclude domain names that don't have image accessible \n",
    "train_domain_names_list = [img_id.split('_')[0] for img_id in train_df['first_image_id'].tolist()]\n",
    "train_domain_names_set = set(train_domain_names_list)\n",
    "train_domain_names_dict = dict()\n",
    "domain_label_id = 0\n",
    "\n",
    "for domain_name in train_domain_names_set:\n",
    "    train_domain_names_dict[domain_name] = domain_label_id\n",
    "    domain_label_id += 1\n",
    "\n",
    "train_domain_names_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>image_id(s)</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>665333038944002048</td>\n",
       "      <td>Tristesse...üò¢üôè \\n#Bataclan sold out, musiciens...</td>\n",
       "      <td>5.547267e+08</td>\n",
       "      <td>Louise_Officiel</td>\n",
       "      <td>attacks_paris_1</td>\n",
       "      <td>Sat Nov 14 00:58:52 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>665324167785410560</td>\n",
       "      <td>RT @Proyecto40: #√öltimaHora Espectacular fotog...</td>\n",
       "      <td>2.827010e+09</td>\n",
       "      <td>MarinoCarril</td>\n",
       "      <td>attacks_paris_1</td>\n",
       "      <td>Sat Nov 14 00:23:37 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>665333370205765632</td>\n",
       "      <td>RT @Javivi1976: #Bataclan esta noche antes de ...</td>\n",
       "      <td>3.776037e+08</td>\n",
       "      <td>MireiaMaroto</td>\n",
       "      <td>attacks_paris_1</td>\n",
       "      <td>Sat Nov 14 01:00:11 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>665326188735295489</td>\n",
       "      <td>RT @Pizzigatas: El hombre tiene que establecer...</td>\n",
       "      <td>1.102841e+08</td>\n",
       "      <td>maria_cabrera</td>\n",
       "      <td>attacks_paris_1</td>\n",
       "      <td>Sat Nov 14 00:31:39 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>665389341141659648</td>\n",
       "      <td>üá´üá∑ #Paris https://t.co/zjjRPC7USm</td>\n",
       "      <td>1.653118e+07</td>\n",
       "      <td>RaycMolina</td>\n",
       "      <td>attacks_paris_1</td>\n",
       "      <td>Sat Nov 14 04:42:35 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>700662094107119616</td>\n",
       "      <td>14 children! 14 different fathers! All of them...</td>\n",
       "      <td>6.973105e+07</td>\n",
       "      <td>ErrBodyLuvsCris</td>\n",
       "      <td>woman_14_children_1</td>\n",
       "      <td>Fri Feb 19 12:43:55 +0000 2016</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>700638809155710977</td>\n",
       "      <td>Meet The Woman Who Has Given Birth To 14 Child...</td>\n",
       "      <td>4.912947e+09</td>\n",
       "      <td>EyoawansBlog</td>\n",
       "      <td>woman_14_children_1</td>\n",
       "      <td>Fri Feb 19 11:11:23 +0000 2016</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>700618091886047232</td>\n",
       "      <td>RT @Viasat1Ghana: Woman, 36, gives birth to 14...</td>\n",
       "      <td>3.245410e+08</td>\n",
       "      <td>NanaEssilfie</td>\n",
       "      <td>woman_14_children_1</td>\n",
       "      <td>Fri Feb 19 09:49:04 +0000 2016</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>700569502874992640</td>\n",
       "      <td>Woman Breaks World Record With 14 Children fro...</td>\n",
       "      <td>4.068154e+08</td>\n",
       "      <td>Abiola_j360ent</td>\n",
       "      <td>woman_14_children_2</td>\n",
       "      <td>Fri Feb 19 06:36:00 +0000 2016</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>700569797545881600</td>\n",
       "      <td>RT @Abiola_j360ent: Woman Breaks World Record ...</td>\n",
       "      <td>2.464708e+09</td>\n",
       "      <td>iam_Spanzy</td>\n",
       "      <td>woman_14_children_2</td>\n",
       "      <td>Fri Feb 19 06:37:10 +0000 2016</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 post_id                                          post_text  \\\n",
       "60    665333038944002048  Tristesse...üò¢üôè \\n#Bataclan sold out, musiciens...   \n",
       "61    665324167785410560  RT @Proyecto40: #√öltimaHora Espectacular fotog...   \n",
       "62    665333370205765632  RT @Javivi1976: #Bataclan esta noche antes de ...   \n",
       "63    665326188735295489  RT @Pizzigatas: El hombre tiene que establecer...   \n",
       "64    665389341141659648                  üá´üá∑ #Paris https://t.co/zjjRPC7USm   \n",
       "...                  ...                                                ...   \n",
       "2172  700662094107119616  14 children! 14 different fathers! All of them...   \n",
       "2173  700638809155710977  Meet The Woman Who Has Given Birth To 14 Child...   \n",
       "2174  700618091886047232  RT @Viasat1Ghana: Woman, 36, gives birth to 14...   \n",
       "2175  700569502874992640  Woman Breaks World Record With 14 Children fro...   \n",
       "2176  700569797545881600  RT @Abiola_j360ent: Woman Breaks World Record ...   \n",
       "\n",
       "           user_id         username          image_id(s)  \\\n",
       "60    5.547267e+08  Louise_Officiel      attacks_paris_1   \n",
       "61    2.827010e+09     MarinoCarril      attacks_paris_1   \n",
       "62    3.776037e+08     MireiaMaroto      attacks_paris_1   \n",
       "63    1.102841e+08    maria_cabrera      attacks_paris_1   \n",
       "64    1.653118e+07       RaycMolina      attacks_paris_1   \n",
       "...            ...              ...                  ...   \n",
       "2172  6.973105e+07  ErrBodyLuvsCris  woman_14_children_1   \n",
       "2173  4.912947e+09     EyoawansBlog  woman_14_children_1   \n",
       "2174  3.245410e+08     NanaEssilfie  woman_14_children_1   \n",
       "2175  4.068154e+08   Abiola_j360ent  woman_14_children_2   \n",
       "2176  2.464708e+09       iam_Spanzy  woman_14_children_2   \n",
       "\n",
       "                           timestamp label  \n",
       "60    Sat Nov 14 00:58:52 +0000 2015  fake  \n",
       "61    Sat Nov 14 00:23:37 +0000 2015  fake  \n",
       "62    Sat Nov 14 01:00:11 +0000 2015  fake  \n",
       "63    Sat Nov 14 00:31:39 +0000 2015  fake  \n",
       "64    Sat Nov 14 04:42:35 +0000 2015  fake  \n",
       "...                              ...   ...  \n",
       "2172  Fri Feb 19 12:43:55 +0000 2016  fake  \n",
       "2173  Fri Feb 19 11:11:23 +0000 2016  fake  \n",
       "2174  Fri Feb 19 09:49:04 +0000 2016  fake  \n",
       "2175  Fri Feb 19 06:36:00 +0000 2016  fake  \n",
       "2176  Fri Feb 19 06:37:10 +0000 2016  fake  \n",
       "\n",
       "[1040 rows x 7 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define image transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_size = 128\n",
    "# pretrained_size = 256\n",
    "pretrained_size = 224\n",
    "pretrained_means = [0.485, 0.456, 0.406]\n",
    "pretrained_stds= [0.229, 0.224, 0.225]\n",
    "\n",
    "# train_transforms = transforms.Compose([\n",
    "#                            transforms.Resize(pretrained_size),\n",
    "#                            transforms.RandomRotation(5),\n",
    "#                            transforms.RandomHorizontalFlip(0.5),\n",
    "#                            transforms.RandomCrop(pretrained_size, padding = 10),\n",
    "#                            transforms.ToTensor(),\n",
    "#                            transforms.Normalize(mean = pretrained_means, \n",
    "#                                                 std = pretrained_stds)\n",
    "#                        ])\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ])\n",
    "\n",
    "# trial_transforms = transforms.Compose([\n",
    "#                            transforms.Resize(pretrained_size),\n",
    "#                            transforms.CenterCrop(pretrained_size),\n",
    "#                            transforms.ToTensor(),\n",
    "#                            transforms.Normalize(mean = pretrained_means, \n",
    "#                                                 std = pretrained_stds)\n",
    "#                        ])\n",
    "\n",
    "test_transforms = train_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip pretrained model for image encoding\n",
    "\n",
    "clip_pretrained = SentenceTransformer('clip-ViT-B-32')\n",
    "\n",
    "# Laser model for text encoding\n",
    "\n",
    "laser_model = Laser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-define Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = listdir(train_img_dir)\n",
    "images.extend(listdir(test_img_dir))\n",
    "\n",
    "jpg = []\n",
    "png=[]\n",
    "jpeg=[]\n",
    "gif = []\n",
    "\n",
    "for i in images:\n",
    "    name,ext = i.split('.')[0],i.split('.')[-1]\n",
    "    eval(ext).append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extension_of_file(file_name):\n",
    "    if file_name in jpg:\n",
    "        return '.jpg'\n",
    "    elif file_name in png:\n",
    "        return '.png'\n",
    "    elif file_name in jpeg:\n",
    "        return '.jpeg'\n",
    "    else:\n",
    "        return '.gif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterDataset(Dataset):\n",
    "    \"\"\"Twitter dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, root_dir, domain_labels_dict, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                to the image.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.domain_labels_dict = domain_labels_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def read_and_process_image(self, list_of_images):\n",
    "        X = [] \n",
    "        for image in tqdm(list_of_images):\n",
    "            X.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (length,width), interpolation=cv2.INTER_CUBIC))  \n",
    "        return X\n",
    "    \n",
    "    def get_news_domain(self, idx):\n",
    "        img_id = self.df.iloc[idx, -1]\n",
    "        news_domain = img_id.split('_')[0]\n",
    "        return news_domain\n",
    "    \n",
    "    def get_extension_of_file(self, file_name):\n",
    "        if file_name in jpg:\n",
    "            return '.jpg'\n",
    "        elif file_name in png:\n",
    "            return '.png'\n",
    "        elif file_name in jpeg:\n",
    "            return '.jpeg'\n",
    "        else:\n",
    "            return '.gif'\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.df.iloc[idx, -1]) + self.get_extension_of_file(self.df.iloc[idx, -1])  # \"image_id(s)\"\n",
    "        news_image = Image.open(img_name)#.convert(\"RGB\")   # convert to RGB is important\n",
    "        news_image = torch.Tensor(clip_pretrained.encode(news_image))\n",
    "        labels = self.df.iloc[idx, -2]   # label\n",
    "        \n",
    "        if labels == 'real':\n",
    "            labels = 0\n",
    "        else:\n",
    "            labels = 1\n",
    "            \n",
    "        labels = np.array(labels)\n",
    "        labels = labels.astype('long')\n",
    "        \n",
    "        news_text = self.df.iloc[idx, 1]   # post_text\n",
    "        news_text = torch.Tensor(laser_model.embed_sentences(news_text, lang='en'))\n",
    "        \n",
    "        news_domain = self.get_news_domain(idx)\n",
    "        news_domain_label = self.domain_labels_dict[news_domain]\n",
    "        \n",
    "        news_domain_label = np.array(news_domain_label)\n",
    "        news_domain_label = news_domain_label.astype('long')\n",
    "        \n",
    "        sample = {'news_image': news_image, 'labels': labels, 'news_text': news_text, 'news_domain_label': news_domain_label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['news_image'] = self.transform(news_image)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterTestset(Dataset):\n",
    "    \"\"\"Twitter dataset testset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def read_and_process_image(self, list_of_images):\n",
    "        X = [] \n",
    "        for image in tqdm(list_of_images):\n",
    "            X.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (length,width), interpolation=cv2.INTER_CUBIC))  \n",
    "        return X\n",
    "    \n",
    "    def get_extension_of_file(self, file_name):\n",
    "        if file_name in jpg:\n",
    "            return '.jpg'\n",
    "        elif file_name in png:\n",
    "            return '.png'\n",
    "        elif file_name in jpeg:\n",
    "            return '.jpeg'\n",
    "        else:\n",
    "            return '.gif'\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.df.iloc[idx, 4]) + self.get_extension_of_file(self.df.iloc[idx, 4])\n",
    "        news_image = Image.open(img_name)#.convert(\"RGB\")   # convert to RGB is important\n",
    "        news_image = torch.Tensor(clip_pretrained.encode(news_image))\n",
    "        labels = self.df.iloc[idx, -1]   # label\n",
    "        \n",
    "        if labels == 'real':\n",
    "            labels = 0\n",
    "        else:\n",
    "            labels = 1\n",
    "            \n",
    "        labels = np.array(labels)\n",
    "        labels = labels.astype('long')\n",
    "        \n",
    "        news_text = self.df.iloc[idx, 1]   # post_text\n",
    "        news_text = torch.Tensor(laser_model.embed_sentences(news_text, lang='en'))\n",
    "        \n",
    "        \n",
    "        sample = {'news_image': news_image, 'news_text': news_text, 'labels': labels}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['news_image'] = self.transform(news_image)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the train and trial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '~/adversarial_learning/MVAE/mediaeval2016/'\n",
    "# train_data = MAMIDataset(train_root_dir + 'training.csv', train_root_dir, train_transforms)\n",
    "train_data = TwitterDataset(train_df, train_img_dir, train_domain_names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = MAMIDataset(train_root_dir + 'training.csv', train_root_dir, train_transforms)\n",
    "test_data = TwitterTestset(test_df, test_img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALID_RATIO = 0.9\n",
    "\n",
    "# n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "# n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "# train_data, valid_data = data.random_split(train_data, \n",
    "#                                            [n_train_examples, n_valid_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_data = copy.deepcopy(valid_data)\n",
    "# valid_data.dataset.transform = trial_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 13407\n",
      "Number of testing examples: 1059\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "# print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create batch iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = data.DataLoader(train_data, \n",
    "                                 shuffle = True, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "# valid_iterator = data.DataLoader(valid_data, \n",
    "#                                  batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator = data.DataLoader(test_data, \n",
    "                                batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct VAE class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GateModule(nn.Module):\n",
    "    \n",
    "    '''\n",
    "    A simple gate implemented with\n",
    "    - a linear layer\n",
    "    - a sigmoid layer\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, in_dim):\n",
    "        super(GateModule, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.gate = nn.Linear(in_dim, 1)\n",
    "        self.prob = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        score = self.gate(x)\n",
    "        score = self.prob(score)\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    '''\n",
    "    Gate is applied only to the text input\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, zsize, output_dim=2):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.zsize = zsize\n",
    "        self.fc1 = nn.Linear(zsize, zsize)   # 4 * 4 is the current size of the image\n",
    "        self.fc2 = nn.Linear(zsize, zsize)\n",
    "\n",
    "        ######\n",
    "        # multi-tasks sub-networks\n",
    "        self.fc_news = nn.Linear(zsize, output_dim)\n",
    "        self.fc_domain = nn.Linear(zsize, 15)\n",
    "        \n",
    "        \n",
    "        # encoder layers\n",
    "        self.enc_txt_fc = nn.Linear(1024, int(0.5 * zsize))\n",
    "        self.enc_img_fc1 = nn.Linear(512, int(0.5 * zsize))\n",
    "#         self.enc_img_fc2 = nn.Linear(1024, int(0.5 * zsize))\n",
    "        \n",
    "        # decoder layers\n",
    "        self.dec_txt_fc = nn.Linear(zsize, 1024)\n",
    "        self.dec_img_fc1 = nn.Linear(zsize, 512)\n",
    "#         self.dec_img_fc2 = nn.Linear(1024, 2048)\n",
    "\n",
    "        # batch normalizations\n",
    "        self.enc_txt_bn = nn.BatchNorm1d(num_features=int(0.5 * zsize))\n",
    "        self.enc_img_bn1 = nn.BatchNorm1d(num_features=int(0.5 * zsize))\n",
    "#         self.enc_img_bn2 = nn.BatchNorm1d(num_features=int(0.5 * zsize))\n",
    "        \n",
    "        self.dec_txt_bn = nn.BatchNorm1d(num_features=1024)\n",
    "        self.dec_img_bn1 = nn.BatchNorm1d(num_features=512)\n",
    "#         self.dec_img_bn2 = nn.BatchNorm1d(num_features=2048)\n",
    "        \n",
    "        # dropout\n",
    "        self.dropout_txt_enc = nn.Dropout(0.2)\n",
    "        self.dropout_img_enc = nn.Dropout(0.2)\n",
    "        self.dropout_txt_dec = nn.Dropout(0.2)\n",
    "        self.dropout_img_dec = nn.Dropout(0.2)\n",
    "        \n",
    "        # gated unit\n",
    "        self.gated_unit = GateModule(1024)  # text embedding dimension\n",
    "        \n",
    "        \n",
    "    def img_encode(self, x_img):\n",
    "#         _, x_img = self.resnet_pretrained(x_img)\n",
    "        x_img = F.relu(self.dropout_img_enc(self.enc_img_bn1(self.enc_img_fc1(x_img))))\n",
    "#         x_img = F.relu(self.enc_img_fc2(x_img))\n",
    "        \n",
    "        return x_img   # [bs, 2048]\n",
    "\n",
    "    def txt_encode(self, x_txt):\n",
    "\n",
    "        gate = self.gated_unit(x_txt)\n",
    "        x_txt = x_txt * gate\n",
    "        \n",
    "        x_txt = x_txt.view(x_txt.shape[0], 1024)\n",
    "        x_txt = F.relu(self.dropout_txt_enc(self.enc_txt_bn(self.enc_txt_fc(x_txt))))\n",
    "        return x_txt, gate   # [bs, 0.5 * zsize]\n",
    "\n",
    "    def encode(self, x_img, x_txt):\n",
    "        \n",
    "        x_img = self.img_encode(x_img)\n",
    "        \n",
    "        x_txt, gate = self.txt_encode(x_txt)\n",
    "        \n",
    "        # concate x_img and x_txt\n",
    "        x = torch.cat((x_txt, x_img), 1)\n",
    "        \n",
    "        h1 = self.fc1(x)   # mu\n",
    "        h2 = self.fc2(x)   # logvar\n",
    "        return h1, h2, gate\n",
    "    \n",
    "    def subtask_news(self, z):\n",
    "        \n",
    "        h = self.fc_news(z)\n",
    "        return h\n",
    "    \n",
    "    def subtask_domain(self, z):\n",
    "        \n",
    "        h = self.fc_domain(z)\n",
    "        return h\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, x):\n",
    "#         x = x.view(x.shape[0], self.zsize)   # flatten\n",
    "\n",
    "        # Decoding txt\n",
    "        dec_x_txt = F.relu(self.dropout_txt_dec(self.dec_txt_bn(self.dec_txt_fc(x))))\n",
    "        \n",
    "        # Decoding img\n",
    "        dec_x_img = F.relu(self.dropout_img_dec(self.dec_img_bn1(self.dec_img_fc1(x))))\n",
    "#         dec_x_img = F.relu(self.dec_img_fc2(dec_x_img))\n",
    "        \n",
    "        return dec_x_img, dec_x_txt\n",
    "\n",
    "    def forward(self, x_img, x_txt):\n",
    "        mu, logvar, gate = self.encode(x_img, x_txt)\n",
    "        mu = mu.squeeze()\n",
    "        logvar = logvar.squeeze()\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "\n",
    "        y_news = self.subtask_news(z)\n",
    "        y_domain = self.subtask_domain(z)\n",
    "        \n",
    "        y_pred = dict()\n",
    "        y_pred[\"news\"] = y_news\n",
    "        y_pred[\"domain\"] = y_domain\n",
    "        \n",
    "        dec_x_img, dec_x_txt = self.decode(z.view(-1, self.zsize))\n",
    "        \n",
    "        return dec_x_img, dec_x_txt, mu, logvar, y_pred, gate\n",
    "\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    '''\n",
    "    Gate is applied to both the text input & image input\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, zsize, output_dim=2):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.zsize = zsize\n",
    "        self.fc1 = nn.Linear(zsize, zsize)   # 4 * 4 is the current size of the image\n",
    "        self.fc2 = nn.Linear(zsize, zsize)\n",
    "\n",
    "        ######\n",
    "        # multi-tasks sub-networks\n",
    "        self.fc_news = nn.Linear(zsize, output_dim)\n",
    "        self.fc_domain = nn.Linear(zsize, 15)\n",
    "        \n",
    "        \n",
    "        # encoder layers\n",
    "        self.enc_txt_fc = nn.Linear(1024, int(0.5 * zsize))\n",
    "        self.enc_img_fc1 = nn.Linear(512, int(0.5 * zsize))\n",
    "#         self.enc_img_fc2 = nn.Linear(1024, int(0.5 * zsize))\n",
    "        \n",
    "        # decoder layers\n",
    "        self.dec_txt_fc = nn.Linear(zsize, 1024)\n",
    "        self.dec_img_fc1 = nn.Linear(zsize, 512)\n",
    "#         self.dec_img_fc2 = nn.Linear(1024, 2048)\n",
    "\n",
    "        # batch normalizations\n",
    "        self.enc_txt_bn = nn.BatchNorm1d(num_features=int(0.5 * zsize))\n",
    "        self.enc_img_bn1 = nn.BatchNorm1d(num_features=int(0.5 * zsize))\n",
    "#         self.enc_img_bn2 = nn.BatchNorm1d(num_features=int(0.5 * zsize))\n",
    "        \n",
    "        self.dec_txt_bn = nn.BatchNorm1d(num_features=1024)\n",
    "        self.dec_img_bn1 = nn.BatchNorm1d(num_features=512)\n",
    "#         self.dec_img_bn2 = nn.BatchNorm1d(num_features=2048)\n",
    "        \n",
    "        # dropout\n",
    "        self.dropout_txt_enc = nn.Dropout(0.2)\n",
    "        self.dropout_img_enc = nn.Dropout(0.2)\n",
    "        self.dropout_txt_dec = nn.Dropout(0.2)\n",
    "        self.dropout_img_dec = nn.Dropout(0.2)\n",
    "        \n",
    "        # gated unit\n",
    "        self.gate = GateModule(zsize)  # text embedding dimension\n",
    "        \n",
    "        \n",
    "    def img_encode(self, x_img):\n",
    "#         _, x_img = self.resnet_pretrained(x_img)\n",
    "        x_img = F.relu(self.dropout_img_enc(self.enc_img_bn1(self.enc_img_fc1(x_img))))\n",
    "#         x_img = F.relu(self.enc_img_fc2(x_img))\n",
    "        \n",
    "        return x_img   # [bs, 2048]\n",
    "\n",
    "    def txt_encode(self, x_txt):\n",
    "\n",
    "        x_txt = x_txt.view(x_txt.shape[0], 1024)\n",
    "        x_txt = F.relu(self.dropout_txt_enc(self.enc_txt_bn(self.enc_txt_fc(x_txt))))\n",
    "        return x_txt  # [bs, 0.5 * zsize]\n",
    "\n",
    "    def encode(self, x_img, x_txt):\n",
    "        \n",
    "        x_img = self.img_encode(x_img)\n",
    "        \n",
    "        x_txt = self.txt_encode(x_txt)\n",
    "        \n",
    "        # concate x_img and x_txt\n",
    "        x = torch.cat((x_txt, x_img), 1)\n",
    "        \n",
    "        p = self.gate(x)\n",
    "        \n",
    "        x = torch.cat((p * x_txt, (1 - p) * x_img), 1)\n",
    "        \n",
    "        h1 = self.fc1(x)   # mu\n",
    "        h2 = self.fc2(x)   # logvar\n",
    "        return h1, h2, p\n",
    "    \n",
    "    def subtask_news(self, z):\n",
    "        \n",
    "        h = self.fc_news(z)\n",
    "        return h\n",
    "    \n",
    "    def subtask_domain(self, z):\n",
    "        \n",
    "        h = self.fc_domain(z)\n",
    "        return h\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, x):\n",
    "#         x = x.view(x.shape[0], self.zsize)   # flatten\n",
    "\n",
    "        # Decoding txt\n",
    "        dec_x_txt = F.relu(self.dropout_txt_dec(self.dec_txt_bn(self.dec_txt_fc(x))))\n",
    "        \n",
    "        # Decoding img\n",
    "        dec_x_img = F.relu(self.dropout_img_dec(self.dec_img_bn1(self.dec_img_fc1(x))))\n",
    "#         dec_x_img = F.relu(self.dec_img_fc2(dec_x_img))\n",
    "        \n",
    "        return dec_x_img, dec_x_txt\n",
    "\n",
    "    def forward(self, x_img, x_txt):\n",
    "        mu, logvar, p = self.encode(x_img, x_txt)\n",
    "        mu = mu.squeeze()\n",
    "        logvar = logvar.squeeze()\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "\n",
    "        y_news = self.subtask_news(z)\n",
    "        y_domain = self.subtask_domain(z)\n",
    "        \n",
    "        y_pred = dict()\n",
    "        y_pred[\"news\"] = y_news\n",
    "        y_pred[\"domain\"] = y_domain\n",
    "        \n",
    "        dec_x_img, dec_x_txt = self.decode(z.view(-1, self.zsize))\n",
    "        \n",
    "        return dec_x_img, dec_x_txt, mu, logvar, y_pred, p\n",
    "\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x_img, recon_x_txt, x_img, x_txt, mu, logvar):\n",
    "    BCE_img = torch.mean((recon_x_img - x_img)**2)\n",
    "    BCE_txt = torch.mean((recon_x_txt - x_txt)**2)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.mean(torch.mean(1 + logvar - mu.pow(2) - logvar.exp(), 1))\n",
    "    return BCE_img, BCE_txt, KLD * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"GatedVAE-uni-all-fake.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    name_dict = dict()\n",
    "    name_dict[\"news\"] = 0\n",
    "    name_dict[\"domain\"] = 1\n",
    "    \n",
    "    #batch_size = 32\n",
    "    z_size = 512\n",
    "#     z_size = 1024\n",
    "    vae = VAE(z_size)\n",
    "    vae.cuda()\n",
    "    vae.train()\n",
    "    vae.weight_init(mean=0, std=0.02)\n",
    "\n",
    "    lr = 0.0001\n",
    "\n",
    "    vae_optimizer = optim.Adam(vae.parameters(), lr=lr, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion.to(device)\n",
    " \n",
    "    train_epoch = 30\n",
    "\n",
    "    \n",
    "    dataloader = train_iterator\n",
    "    \n",
    "    f1_max = 0\n",
    "    max_acc = 0\n",
    "    \n",
    "    for epoch in range(train_epoch):\n",
    "        vae.train()\n",
    "\n",
    "        rec_txt_loss = 0\n",
    "        rec_img_loss = 0\n",
    "        kl_loss = 0\n",
    "        subtask_news_loss = 0\n",
    "        subtask_domain_loss = 0\n",
    "\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        if (epoch + 1) % 8 == 0:\n",
    "            vae_optimizer.param_groups[0]['lr'] /= 4\n",
    "#             print(\"learning rate change!\")\n",
    "            f.write(\"learning rate change! The learning rate is %1.4f now\\n\" % (lr))\n",
    "\n",
    "#         i = 0\n",
    "        acc = 0\n",
    "        num = 0\n",
    "        for i, data in tqdm(enumerate(dataloader, 0), desc='iterations'):\n",
    "        #for x in batches:\n",
    "            vae.train()\n",
    "            \n",
    "            #inputs, classes = data\n",
    "            img_inputs = data['news_image']\n",
    "            img_inputs = img_inputs.to(device)\n",
    "\n",
    "            txt_inputs = data[\"news_text\"]\n",
    "            txt_inputs = txt_inputs.to(device)\n",
    "            \n",
    "            classes = data['labels']\n",
    "            \n",
    "            domain_classes = data['news_domain_label']\n",
    "            \n",
    "            # multi-task labels\n",
    "            classes_news = classes\n",
    "            classes_domain = domain_classes\n",
    "            \n",
    "            img_inputs, txt_inputs, classes_news = Variable(img_inputs), Variable(txt_inputs), Variable(classes_news)\n",
    "            classes_domain = Variable(classes_domain)\n",
    "        \n",
    "            img_inputs = img_inputs.to(device)\n",
    "            txt_inputs = txt_inputs.to(device)\n",
    "            classes_news = classes_news.to(device)\n",
    "            classes_domain = classes_domain.to(device)\n",
    "            \n",
    "            vae.zero_grad()\n",
    "            rec_img, rec_txt, mu, logvar, y_pred, p = vae(img_inputs, txt_inputs)\n",
    "#             if i == 0:\n",
    "#                 print(p[:10])\n",
    "\n",
    "            loss_re_img, loss_re_txt, loss_kl = loss_function(rec_img, rec_txt, img_inputs, txt_inputs, mu, logvar)\n",
    "            loss_subtask_news = criterion(y_pred[\"news\"], classes_news)\n",
    "            loss_subtask_domain = criterion(y_pred[\"domain\"], classes_domain)\n",
    "\n",
    "            \n",
    "            (loss_re_img + loss_re_txt + loss_kl + loss_subtask_news + loss_subtask_domain).backward() #\\\n",
    "#              + loss_subtask_shaming + loss_subtask_stereotype + loss_subtask_objectification\\\n",
    "#              + loss_subtask_violence).backward()\n",
    "            \n",
    "            vae_optimizer.step()\n",
    "            rec_img_loss += loss_re_img.item()\n",
    "            rec_txt_loss += loss_re_txt.item()\n",
    "            \n",
    "            kl_loss += loss_kl.item()\n",
    "            subtask_news_loss += loss_subtask_news.item()\n",
    "            subtask_domain_loss += loss_subtask_domain.item()\n",
    "            \n",
    "            # Calculate batch accuracy\n",
    "            _, top_pred = y_pred[\"news\"].topk(1, 1)\n",
    "            y = classes_news.cpu()\n",
    "            batch_size = y.shape[0]\n",
    "            top_pred = top_pred.cpu().view(batch_size)\n",
    "            acc += sum(top_pred == y).item()\n",
    "            num += batch_size\n",
    "\n",
    "            #############################################\n",
    "\n",
    "            epoch_end_time = time.time()\n",
    "            per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "\n",
    "            # report losses and save samples each 60 iterations\n",
    "            m = len(dataloader)\n",
    "            i += 1\n",
    "            if i % m == 0:\n",
    "                rec_txt_loss /= m\n",
    "                rec_img_loss /= m\n",
    "                kl_loss /= m\n",
    "                subtask_news_loss /= m\n",
    "                subtask_domain_loss /= m\n",
    "                \n",
    "#                 print('\\n[%d/%d] - ptime: %.2f, rec img loss: %.9f, rec txt loss: %.9f, KL loss: %.9f, misogynous loss: %.9f, shaming loss: %.9f, stereotype loss: %.9f, objectification loss: %.9f, violence loss: %.9f' % (\n",
    "#                     (epoch + 1), train_epoch, per_epoch_ptime, rec_img_loss, rec_txt_loss, kl_loss, subtask_misogynous_loss, subtask_shaming_loss, subtask_stereotype_loss, subtask_objectification_loss, subtask_violence_loss))\n",
    "\n",
    "#                 f.write('\\n[%d/%d] - ptime: %.2f, rec img loss: %.9f, rec txt loss: %.9f, KL loss: %.9f, misogynous loss: %.9f, shaming loss: %.9f, stereotype loss: %.9f, objectification loss: %.9f, violence loss: %.9f\\n' % (\n",
    "#                     (epoch + 1), train_epoch, per_epoch_ptime, rec_img_loss, rec_txt_loss, kl_loss, subtask_misogynous_loss, subtask_shaming_loss, subtask_stereotype_loss, subtask_objectification_loss, subtask_violence_loss))\n",
    "                f.write('\\n[%d/%d] - ptime: %.2f, rec img loss: %.9f, rec txt loss: %.9f, KL loss: %.9f, news loss: %.9f, domain loss: %.9f\\n' % (\n",
    "                    (epoch + 1), train_epoch, per_epoch_ptime, rec_img_loss, rec_txt_loss, kl_loss, subtask_news_loss, subtask_domain_loss))\n",
    "                rec_txt_loss = 0\n",
    "                rec_img_loss = 0\n",
    "                kl_loss = 0\n",
    "                with torch.no_grad():\n",
    "#                     test_loss, test_acc, test_accuracy, test_f1, test_recall, test_precision = evaluate(vae, valid_iterator, criterion, device, \"misogynous\")\n",
    "                    test_loss, test_acc, test_accuracy, test_f1, test_recall, test_precision = evaluate(vae, test_iterator, criterion, device)\n",
    "                    f.write(f'Test subtask news loss: {test_loss:.3f} | Test Acc @1: {test_acc*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask news accuracy: {test_accuracy*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask news f1: {test_f1*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask news recall: {test_recall*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask news precision: {test_precision*100:6.2f}%\\n')\n",
    "                    \n",
    "                    \n",
    "                    acc /= num\n",
    "                    print(f'num_correct: {acc}\\n')\n",
    "                    print(f'total_num: {num}\\n')\n",
    "                    f.write(f'Training accuracy: {acc*100:6.2f}%\\n')\n",
    "                    \n",
    "                    if test_f1*100 >= f1_max:\n",
    "                        \n",
    "                        torch.save(vae.state_dict(), \"GatedVAE-uni-all-fake-%d.pkl\" % (epoch+1))\n",
    "                        f.write(\"Epoch [%d/%d]: test f1 on news improves from %.2f to %.2f, saving training results\\n\" % (epoch+1, train_epoch, f1_max, test_f1))\n",
    "                        f1_max = test_f1*100\n",
    "\n",
    "        f.flush()\n",
    "\n",
    "    f.write(\"Training finish!... save training results\\n\")\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    with torch.no_grad():\n",
    "        batch_size = y.shape[0]\n",
    "        _, top_pred = y_pred.topk(1, 1)\n",
    "        top_pred = top_pred.t()\n",
    "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
    "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim = True)\n",
    "        acc_1 = correct_1 / batch_size\n",
    "    \n",
    "    top_pred = top_pred.cpu().view(batch_size)\n",
    "    y = y.cpu()\n",
    "    \n",
    "    accuracy = accuracy_score(y, top_pred)\n",
    "    #print(\"accuracy: {}\".format(accuracy))\n",
    "\n",
    "    f1 = f1_score(y, top_pred)\n",
    "#     print(top_pred)\n",
    "    #print(\"f1: {}\".format(f1))\n",
    "\n",
    "    recall = recall_score(y, top_pred)\n",
    "    #print(\"recall: {}\".format(recall))\n",
    "\n",
    "    precision = precision_score(y, top_pred)\n",
    "    #print(\"precision: {}\".format(precision))\n",
    "\n",
    "    cm = confusion_matrix(y, top_pred)\n",
    "    #print(\"cm: {}\".format(cm))\n",
    "    return acc_1, accuracy, f1, recall, precision, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device, subtask_name=\"news\"):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, data in tqdm(enumerate(iterator, 0), desc='iterations'):\n",
    "\n",
    "            x_img = data['news_image']\n",
    "            x_img = x_img.to(device)\n",
    "            \n",
    "            x_txt = data['news_text']\n",
    "            x_txt = x_txt.to(device)\n",
    "            \n",
    "            \n",
    "            y = data['labels']\n",
    "            batch_size = y.shape[0]\n",
    "            \n",
    "            x_img, x_txt = x_img.to(device), x_txt.to(device)\n",
    "\n",
    "            _, _, _, _, y_pred, gate = model(x_img, x_txt)\n",
    "                \n",
    "                \n",
    "            y_true_all += y.tolist()\n",
    "            _, top_pred = y_pred[\"news\"].topk(1, 1)\n",
    "            top_pred = top_pred.t()\n",
    "            top_pred = top_pred.cpu().view(batch_size)\n",
    "            y_pred_all += top_pred.tolist()\n",
    "            \n",
    "            y = y.to(device)\n",
    "            loss = criterion(y_pred[\"news\"], y)\n",
    "            epoch_loss += loss.item()\n",
    "                \n",
    "                \n",
    "    epoch_accuracy = accuracy_score(y_true_all, y_pred_all)\n",
    "    #print(\"accuracy: {}\".format(accuracy))\n",
    "\n",
    "    epoch_f1 = f1_score(y_true_all, y_pred_all)\n",
    "#     print(top_pred)\n",
    "    #print(\"f1: {}\".format(f1))\n",
    "\n",
    "    epoch_recall = recall_score(y_true_all, y_pred_all)\n",
    "    #print(\"recall: {}\".format(recall))\n",
    "\n",
    "    epoch_precision = precision_score(y_true_all, y_pred_all)\n",
    "    #print(\"precision: {}\".format(precision))\n",
    "                \n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_accuracy, epoch_accuracy, epoch_f1, epoch_recall, epoch_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vae = main()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, iterator, device):\n",
    "    \n",
    "    name_dict = dict()\n",
    "    name_dict[\"news\"] = 0\n",
    "    \n",
    "    y_test = dict()\n",
    "    y_test[\"news\"] = []\n",
    "    \n",
    "    y_true = []\n",
    "    scores = []\n",
    "    \n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, data in tqdm(enumerate(iterator, 0), desc='iterations'):\n",
    "\n",
    "            x_img = data['news_image']\n",
    "            x_img = x_img.to(device)\n",
    "            \n",
    "            x_txt = data['news_text']\n",
    "            label = data['labels']\n",
    "            y_true += label.tolist()\n",
    "            \n",
    "            x_img, x_txt = x_img.to(device), x_txt.to(device)\n",
    "\n",
    "            _, _, _, _, y_pred, gate_score = model(x_img, x_txt)\n",
    "            \n",
    "            scores.append(gate_score.squeeze(axis=1))\n",
    "            \n",
    "            \n",
    "            for subtask_name, subtask_index in name_dict.items():\n",
    "                subtask_y = y_pred[subtask_name].cpu()\n",
    "                for dp in subtask_y:\n",
    "                    if dp[0] >= dp[1]:\n",
    "                        y_test[subtask_name].append(0)\n",
    "                    else:\n",
    "                        y_test[subtask_name].append(1)\n",
    "        \n",
    "    return y_test, y_true, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d330e527bae44329a41c310531255e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iterations: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test, y_true, scores = test(best_VAE, test_iterator, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision_recall_fscore_support(y_true, y_pred, average=None, labels=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
